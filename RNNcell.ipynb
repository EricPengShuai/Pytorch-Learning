{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.12 64-bit ('pytorch_dl': conda)",
   "metadata": {
    "interpreter": {
     "hash": "6b962ed846ab7a2f9c4286c5c9f447c6ba721d3b496bd62adf19906831909870"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "æ¥æºï¼š[bç«™åˆ˜äºŒå¤§äºº--RNNåŸºç¡€ç¯‡](https://www.bilibili.com/video/BV1Y7411d7Ys?p=12)\n",
    "# How to use RNNCell\n",
    "## æ³¨æ„å‡ ä¸ªå‚æ•°\n",
    "1. è¾“å…¥å’Œéšå±‚ï¼ˆè¾“å‡ºï¼‰ç»´åº¦\n",
    "2. åºåˆ—é•¿åº¦\n",
    "3. æ‰¹å¤„ç†å¤§å°\n",
    "\n",
    "- **æ³¨ è°ƒç”¨RNNCellè¿™ä¸ªéœ€è¦å¾ªç¯ï¼Œå¾ªç¯é•¿åº¦å°±æ˜¯åºåˆ—é•¿åº¦**"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "==================== 0 ====================\nInput size: torch.Size([1, 4]) tensor([[ 1.9129, -0.7440,  0.2329,  1.3065]])\nhidden size: torch.Size([1, 2]) tensor([[-0.0790, -0.8957]], grad_fn=<TanhBackward>)\ntensor([[-0.0790, -0.8957]], grad_fn=<TanhBackward>)\n==================== 1 ====================\nInput size: torch.Size([1, 4]) tensor([[-0.6290, -0.2338, -0.2949,  0.3956]])\nhidden size: torch.Size([1, 2]) tensor([[ 0.0170, -0.0005]], grad_fn=<TanhBackward>)\ntensor([[ 0.0170, -0.0005]], grad_fn=<TanhBackward>)\n==================== 2 ====================\nInput size: torch.Size([1, 4]) tensor([[-0.6959,  1.0590, -0.6798,  0.6989]])\nhidden size: torch.Size([1, 2]) tensor([[0.4216, 0.6813]], grad_fn=<TanhBackward>)\ntensor([[0.4216, 0.6813]], grad_fn=<TanhBackward>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "batch_size = 1  # æ‰¹å¤„ç†å¤§å°\n",
    "seq_len = 3     # åºåˆ—é•¿åº¦\n",
    "input_size = 4  # è¾“å…¥ç»´åº¦\n",
    "hidden_size = 2 # éšå±‚ç»´åº¦\n",
    "\n",
    "cell = torch.nn.RNNCell(input_size=input_size, hidden_size=hidden_size)\n",
    "\n",
    "# (seq, batch, features)\n",
    "dataset = torch.randn(seq_len, batch_size, input_size)\n",
    "hidden = torch.zeros(batch_size, hidden_size)\n",
    "\n",
    "# è¿™ä¸ªå¾ªç¯å°±æ˜¯å¤„ç†seq_lené•¿åº¦çš„æ•°æ®\n",
    "for idx, data in enumerate(dataset):\n",
    "    print('=' * 20, idx, '=' * 20)\n",
    "    print('Input size:', data.shape, data)\n",
    "\n",
    "    hidden = cell(data, hidden)\n",
    "\n",
    "    print('hidden size:', hidden.shape, hidden)\n",
    "    print(hidden)"
   ]
  },
  {
   "source": [
    "# How to use RNN\n",
    "## ç¡®å®šå‡ ä¸ªå‚æ•°\n",
    "1. input_sizeå’Œhidden_size: è¾“å…¥ç»´åº¦å’Œéšå±‚ç»´åº¦\n",
    "2. batch_size: æ‰¹å¤„ç†å¤§å°\n",
    "3. seq_len: åºåˆ—é•¿åº¦\n",
    "4. num_layers: éšå±‚æ•°ç›®\n",
    "\n",
    "- **æ³¨ ç›´æ¥è°ƒç”¨RNNè¿™ä¸ªä¸ç”¨å¾ªç¯**\n",
    "- **æ³¨ï¼šå¦‚æœä½¿ç”¨batch_first: if True, the input and output tensors are provided as:(batch_size, seq_len, input_size)**"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "import torch\n",
    "\n",
    "batch_size = 1\n",
    "seq_len = 3\n",
    "input_size = 4\n",
    "hidden_size = 2\n",
    "num_layers = 1\n",
    "\n",
    "cell = torch.nn.RNN(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers)\n",
    "\n",
    "# (seqLen, batchSize, inputSize)\n",
    "inputs = torch.randn(seq_len, batch_size, input_size)\n",
    "hidden = torch.zeros(num_layers, batch_size, hidden_size)\n",
    "\n",
    "out, hidden = cell(inputs, hidden)\n",
    "\n",
    "print('Output size:', out.shape)        # (seq_len, batch_size, hidden_size)\n",
    "print('Output:', out)\n",
    "print('Hidden size:', hidden.shape)     # (num_layers, batch_size, hidden_size)\n",
    "print('Hidden:', hidden)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 23,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Output size: torch.Size([3, 1, 2])\nOutput: tensor([[[ 0.3689,  0.5982]],\n\n        [[ 0.1233,  0.2617]],\n\n        [[-0.3517, -0.7246]]], grad_fn=<StackBackward>)\nHidden size: torch.Size([1, 1, 2])\nHidden: tensor([[[-0.3517, -0.7246]]], grad_fn=<StackBackward>)\n"
     ]
    }
   ]
  },
  {
   "source": [
    "# Example: Using RNNCell\n",
    "## Hello --> ohlol\n",
    "1. é¦–å…ˆéœ€è¦å°†è¾“å…¥çš„å•è¯è½¬æˆå‘é‡`one-hot vector`\n",
    "2. æ³¨æ„input_sizeï¼Œå¦‚ä¸‹å›¾\n",
    "\n",
    "![è½¬åŒ–æˆå‘é‡](https://ericpengshuai.github.io/shen-du-xue-xi/ac81e297adc0/RNN_example.png)\n",
    "\n",
    "## æ³¨æ„äº¤å‰ç†µåœ¨è®¡ç®—lossçš„æ—¶å€™ç»´åº¦å…³ç³»ï¼Œè¿™é‡Œçš„hiddenæ˜¯`([1, 4])`, labelæ˜¯ `([1])`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([5, 1, 4]) torch.Size([5, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "input_size = 4\n",
    "hidden_size = 4\n",
    "batch_size = 1\n",
    "\n",
    "idx2char = ['e', 'h', 'l', 'o']\n",
    "x_data = [1, 0, 2, 3, 3]    # helloä¸­å„ä¸ªå­—ç¬¦çš„ä¸‹æ ‡\n",
    "y_data = [3, 1, 2, 3, 2]    # ohlolä¸­å„ä¸ªå­—ç¬¦çš„ä¸‹æ ‡\n",
    "\n",
    "one_hot_lookup = [[1, 0, 0, 0],\n",
    "                  [0, 1, 0, 0],\n",
    "                  [0, 0, 1, 0],\n",
    "                  [0, 0, 0, 1]]\n",
    "x_one_hot = [one_hot_lookup[x] for x in x_data] # (seqLen, inputSize)\n",
    "\n",
    "inputs = torch.Tensor(x_one_hot).view(-1, batch_size, input_size)\n",
    "labels = torch.LongTensor(y_data).view(-1, 1)   # torch.Tensoré»˜è®¤æ˜¯torch.FloatTensoræ˜¯32ä½æµ®ç‚¹ç±»å‹æ•°æ®ï¼Œtorch.LongTensoræ˜¯64ä½æ•´å‹\n",
    "print(inputs.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, batch_size):\n",
    "        super(Model, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnncell = nn.RNNCell(input_size=self.input_size, hidden_size=self.hidden_size)\n",
    "\n",
    "    def forward(self, inputs, hidden):\n",
    "        hidden = self.rnncell(inputs, hidden)   # (batch_size, hidden_size)\n",
    "        return hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(self.batch_size, self.hidden_size)\n",
    "\n",
    "net = Model(input_size, hidden_size, batch_size)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Predicted string:lhlhh, Epoch [1/15] loss=6.8407\nPredicted string:lllll, Epoch [2/15] loss=5.2957\nPredicted string:lllol, Epoch [3/15] loss=4.9344\nPredicted string:lllol, Epoch [4/15] loss=4.7035\nPredicted string:oolol, Epoch [5/15] loss=4.4781\nPredicted string:oolol, Epoch [6/15] loss=4.2419\nPredicted string:ohlol, Epoch [7/15] loss=3.9733\nPredicted string:ohlol, Epoch [8/15] loss=3.6942\nPredicted string:ohlol, Epoch [9/15] loss=3.4917\nPredicted string:ohloo, Epoch [10/15] loss=3.3837\nPredicted string:ohloo, Epoch [11/15] loss=3.2953\nPredicted string:ohlol, Epoch [12/15] loss=3.1331\nPredicted string:ohlol, Epoch [13/15] loss=2.9294\nPredicted string:ohlol, Epoch [14/15] loss=2.7344\nPredicted string:ohlol, Epoch [15/15] loss=2.5680\n"
     ]
    }
   ],
   "source": [
    "epochs = 15\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    loss = 0\n",
    "    optimizer.zero_grad()\n",
    "    hidden = net.init_hidden()\n",
    "    print('Predicted string:', end='')\n",
    "    for input, label in zip(inputs, labels):\n",
    "        hidden = net(input, hidden)\n",
    "        # æ³¨æ„äº¤å‰ç†µåœ¨è®¡ç®—lossçš„æ—¶å€™ç»´åº¦å…³ç³»ï¼Œè¿™é‡Œçš„hiddenæ˜¯([1, 4]), labelæ˜¯ ([1])\n",
    "        loss += criterion(hidden, label)\n",
    "        _, idx = hidden.max(dim = 1)\n",
    "        print(idx2char[idx.item()], end='')\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(', Epoch [%d/15] loss=%.4f' % (epoch+1, loss.item()))"
   ]
  },
  {
   "source": [
    "# Example: Using RNN\n",
    "## æ³¨æ„`inputs`å’Œ`labels`çš„ç»´åº¦\n",
    "- `inputs`ç»´åº¦æ˜¯: (seqLen, batch_size, input_size)\n",
    "- `labels`ç»´åº¦æ˜¯: (seqLen * batch_size)\n",
    "\n",
    "## æ³¨æ„`outputs`ç»´åº¦ï¼Œå¯¹åº”å’Œ`labels`åšäº¤å‰ç†µçš„ç»´åº¦\n",
    "- `outputs`ç»´åº¦æ˜¯: (seqLen, batch_size, hidden_size)\n",
    "- ä¸ºäº†èƒ½å’Œlabelsåšäº¤å‰ç†µï¼Œéœ€è¦reshapeä¸€ä¸‹: outputs.view(-1, hidden_size)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([5, 1, 4]) torch.Size([5])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "input_size = 4\n",
    "hidden_size = 4\n",
    "batch_size = 1\n",
    "seq_len = 5\n",
    "num_layers = 1\n",
    "\n",
    "idx2char = ['e', 'h', 'l', 'o']\n",
    "x_data = [1, 0, 2, 3, 3]    # helloä¸­å„ä¸ªå­—ç¬¦çš„ä¸‹æ ‡\n",
    "y_data = [3, 1, 2, 3, 2]    # ohlolä¸­å„ä¸ªå­—ç¬¦çš„ä¸‹æ ‡\n",
    "\n",
    "one_hot_lookup = [[1, 0, 0, 0],\n",
    "                  [0, 1, 0, 0],\n",
    "                  [0, 0, 1, 0],\n",
    "                  [0, 0, 0, 1]]\n",
    "x_one_hot = [one_hot_lookup[x] for x in x_data] # (seqLen, inputSize)\n",
    "\n",
    "inputs = torch.Tensor(x_one_hot).view(seq_len, batch_size, input_size)\n",
    "labels = torch.LongTensor(y_data)  \n",
    "print(inputs.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, batch_size, num_layers=1):\n",
    "        super(Model, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.batch_size = batch_size\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn = nn.RNN(input_size=self.input_size, hidden_size=self.hidden_size, )\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        hidden = torch.zeros(self.num_layers, self.batch_size, self.hidden_size)\n",
    "        out, _ = self.rnn(inputs, hidden)    # æ³¨æ„ç»´åº¦æ˜¯(seqLen, batch_size, hidden_size)\n",
    "        return out.view(-1, self.hidden_size) # ä¸ºäº†å®¹æ˜“è®¡ç®—äº¤å‰ç†µè¿™é‡Œè°ƒæ•´ç»´åº¦ä¸º(seqLen * batch_size, hidden_size)\n",
    "\n",
    "net = Model(input_size, hidden_size, batch_size)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Predicted:  ololl, Epoch [1/15] loss = 1.189\nPredicted:  ollll, Epoch [2/15] loss = 1.070\nPredicted:  ollll, Epoch [3/15] loss = 0.976\nPredicted:  ohlll, Epoch [4/15] loss = 0.883\nPredicted:  ohlol, Epoch [5/15] loss = 0.788\nPredicted:  ohlol, Epoch [6/15] loss = 0.715\nPredicted:  ohlol, Epoch [7/15] loss = 0.652\nPredicted:  ohlol, Epoch [8/15] loss = 0.603\nPredicted:  ohlol, Epoch [9/15] loss = 0.570\nPredicted:  ohlol, Epoch [10/15] loss = 0.548\nPredicted:  ohlol, Epoch [11/15] loss = 0.530\nPredicted:  ohlol, Epoch [12/15] loss = 0.511\nPredicted:  ohlol, Epoch [13/15] loss = 0.488\nPredicted:  ohlol, Epoch [14/15] loss = 0.462\nPredicted:  ohlol, Epoch [15/15] loss = 0.439\n"
     ]
    }
   ],
   "source": [
    "epochs = 15\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = net(inputs) \n",
    "    # print(outputs.shape, labels.shape)\n",
    "    # è¿™é‡Œçš„outputsç»´åº¦æ˜¯([seqLen * batch_size, hidden]), labelsç»´åº¦æ˜¯([seqLen])\n",
    "    loss = criterion(outputs, labels) \n",
    "    loss.backward() \n",
    "    optimizer.step()\n",
    "\n",
    "    _, idx = outputs.max(dim=1) \n",
    "    idx = idx.data.numpy() \n",
    "    print('Predicted: ', ''.join([idx2char[x] for x in idx]), end='') \n",
    "    print(', Epoch [%d/15] loss = %.3f' % (epoch + 1, loss.item()))"
   ]
  },
  {
   "source": [
    "# å°†ä¸€ä¸ªå•è¯å˜æˆvector\n",
    "## One-hot encoding of words and characters\n",
    "- one-hot vectors high-dimension --> lower-dimension\n",
    "- one-hot vectors sparse --> dense\n",
    "- one-hot vectors hardcoded   --> learn from data\n",
    "\n",
    "## Embedding\n",
    "![ont_hot_vector VS embedding](https://ericpengshuai.github.io/shen-du-xue-xi/ac81e297adc0/ont_hot_VS_embedding.png)\n",
    "![embedding](https://ericpengshuai.github.io/shen-du-xue-xi/ac81e297adc0/embedding.png)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# parameters\n",
    "num_class = 4 \n",
    "input_size = 4 \n",
    "hidden_size = 8 \n",
    "embedding_size = 10 \n",
    "num_layers = 2 \n",
    "batch_size = 1 \n",
    "seq_len = 5\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.emb = torch.nn.Embedding(input_size, embedding_size)\n",
    "        self.rnn = nn.RNN(input_size=embedding_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_class)\n",
    "\n",
    "    def forward(self, x):\n",
    "        hidden = torch.zeros(num_layers, x.size(0), hidden_size)\n",
    "        x = self.emb(x)                 # (batch, seqLen, embeddingSize) \n",
    "        x, _ = self.rnn(x, hidden)      # è¾“å‡º(ğ’ƒğ’‚ğ’•ğ’„ğ’‰ğ‘ºğ’Šğ’›ğ’†, ğ’”ğ’†ğ’’ğ‘³ğ’†ğ’, hidden_size)\n",
    "        x = self.fc(x)                  # è¾“å‡º(ğ’ƒğ’‚ğ’•ğ’„ğ’‰ğ‘ºğ’Šğ’›ğ’†, ğ’”ğ’†ğ’’ğ‘³ğ’†ğ’, ğ’ğ’–ğ’ğ‘ªğ’ğ’‚ğ’”ğ’”)\n",
    "        return x.view(-1, num_class)    # reshape to use Cross Entropy: (ğ’ƒğ’‚ğ’•ğ’„ğ’‰ğ‘ºğ’Šğ’›ğ’†Ã—ğ’”ğ’†ğ’’ğ‘³ğ’†ğ’, ğ’ğ’–ğ’ğ‘ªğ’ğ’‚ğ’”ğ’”)\n",
    "        \n",
    "net = Model()\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Predicted:  ollll, Epoch [1/15] loss = 1.290\nPredicted:  olooo, Epoch [2/15] loss = 1.071\nPredicted:  ollol, Epoch [3/15] loss = 0.913\nPredicted:  ollol, Epoch [4/15] loss = 0.785\nPredicted:  ollol, Epoch [5/15] loss = 0.660\nPredicted:  ohlol, Epoch [6/15] loss = 0.541\nPredicted:  ohlol, Epoch [7/15] loss = 0.435\nPredicted:  ohlol, Epoch [8/15] loss = 0.343\nPredicted:  ohlol, Epoch [9/15] loss = 0.251\nPredicted:  ohlol, Epoch [10/15] loss = 0.171\nPredicted:  ohlol, Epoch [11/15] loss = 0.121\nPredicted:  ohlol, Epoch [12/15] loss = 0.081\nPredicted:  ohlol, Epoch [13/15] loss = 0.052\nPredicted:  ohlol, Epoch [14/15] loss = 0.036\nPredicted:  ohlol, Epoch [15/15] loss = 0.025\n"
     ]
    }
   ],
   "source": [
    "idx2char = ['e', 'h', 'l', 'o'] \n",
    "x_data = [[1, 0, 2, 2, 3]]  # (batch, seq_len) \n",
    "y_data = [3, 1, 2, 3, 2]    # (batch * seq_len)\n",
    "\n",
    "inputs = torch.LongTensor(x_data)   # Input should be LongTensor: (batchSize, seqLen)\n",
    "labels = torch.LongTensor(y_data)   # Target should be LongTensor: (batchSize * seqLen)\n",
    "\n",
    "epochs = 15\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = net(inputs) \n",
    "    loss = criterion(outputs, labels) \n",
    "    loss.backward() \n",
    "    optimizer.step()\n",
    "\n",
    "    _, idx = outputs.max(dim=1) \n",
    "    idx = idx.data.numpy() \n",
    "    print('Predicted: ', ''.join([idx2char[x] for x in idx]), end='') \n",
    "    print(', Epoch [%d/15] loss = %.3f' % (epoch + 1, loss.item()))"
   ]
  }
 ]
}